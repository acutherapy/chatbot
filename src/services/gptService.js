import OpenAI from 'openai';
import { config } from '../config/index.js';
import { logInfo, logError } from '../utils/logger.js';

class GPTService {
  constructor() {
    this.openai = new OpenAI({
      apiKey: config.openai.apiKey,
    });
    
    // System prompt for clinic chatbot
    this.systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯Šæ‰€å®¢æœåŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºæ‚£è€…æä¾›åŒ»ç–—ä¿¡æ¯å’¨è¯¢å’Œé¢„çº¦æœåŠ¡ã€‚

ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
1. å›ç­”å…³äºè¯Šæ‰€æœåŠ¡ã€åŒ»ç”Ÿä¿¡æ¯ã€æ²»ç–—é¡¹ç›®çš„é—®é¢˜
2. ååŠ©æ‚£è€…è¿›è¡Œé¢„çº¦å®‰æ’
3. æä¾›è¯Šæ‰€åœ°å€ã€è¥ä¸šæ—¶é—´ç­‰åŸºæœ¬ä¿¡æ¯
4. è§£é‡Šå¸¸è§åŒ»ç–—æµç¨‹å’Œæ³¨æ„äº‹é¡¹

é‡è¦è§„åˆ™ï¼š
- åªæä¾›ä¸€èˆ¬æ€§åŒ»ç–—ä¿¡æ¯ï¼Œä¸è¿›è¡Œå…·ä½“è¯Šæ–­
- é‡åˆ°å¤æ‚åŒ»ç–—é—®é¢˜æ—¶ï¼Œå»ºè®®æ‚£è€…å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
- ä¿æŒå‹å¥½ã€ä¸“ä¸šã€è€å¿ƒçš„æœåŠ¡æ€åº¦
- ä½¿ç”¨ç®€æ´æ˜äº†çš„ä¸­æ–‡å›å¤
- å¦‚æœæ— æ³•å›ç­”æŸä¸ªé—®é¢˜ï¼Œè¯šå®å‘ŠçŸ¥å¹¶å»ºè®®è”ç³»è¯Šæ‰€

å½“ç”¨æˆ·è¯¢é—®é¢„çº¦ç›¸å…³é—®é¢˜æ—¶ï¼Œå¯ä»¥æä¾›é¢„çº¦é“¾æ¥æˆ–å»ºè®®è”ç³»è¯Šæ‰€è¿›è¡Œè¯¦ç»†å®‰æ’ã€‚`;

    this.conversationHistory = new Map(); // å­˜å‚¨ç”¨æˆ·å¯¹è¯å†å²
  }

  /**
   * ç”Ÿæˆ AI å›å¤
   * @param {string} userMessage - ç”¨æˆ·æ¶ˆæ¯
   * @param {string} userId - ç”¨æˆ·ID
   * @param {string} platform - å¹³å°ç±»å‹ (web, messenger, instagram)
   * @returns {Promise<string>} AI å›å¤
   */
  async generateResponse(userMessage, userId, platform = 'web') {
    try {
      logInfo('Generating GPT response', { userId, platform, messageLength: userMessage.length });

      // è·å–ç”¨æˆ·å¯¹è¯å†å²
      const conversationHistory = this.getConversationHistory(userId);
      
      // æ„å»ºæ¶ˆæ¯æ•°ç»„
      const messages = [
        { role: 'system', content: this.systemPrompt },
        ...conversationHistory,
        { role: 'user', content: userMessage }
      ];

      // è°ƒç”¨ OpenAI API
      const completion = await this.openai.chat.completions.create({
        model: config.openai.model,
        messages: messages,
        max_tokens: config.openai.maxTokens,
        temperature: config.openai.temperature,
        presence_penalty: 0.1,
        frequency_penalty: 0.1,
      });

      const response = completion.choices[0]?.message?.content?.trim();
      
      if (!response) {
        throw new Error('Empty response from OpenAI');
      }

      // ä¿å­˜å¯¹è¯å†å²
      this.saveConversationHistory(userId, userMessage, response);

      logInfo('GPT response generated successfully', { 
        userId, 
        responseLength: response.length,
        tokensUsed: completion.usage?.total_tokens 
      });

      return response;

    } catch (error) {
      logError('Error generating GPT response', error, { userId, platform });
      
      // è¿”å›å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
      return this.getFallbackResponse(error);
    }
  }

  /**
   * è·å–ç”¨æˆ·å¯¹è¯å†å²
   * @param {string} userId - ç”¨æˆ·ID
   * @returns {Array} å¯¹è¯å†å²æ•°ç»„
   */
  getConversationHistory(userId) {
    const history = this.conversationHistory.get(userId) || [];
    
    // é™åˆ¶å†å²è®°å½•é•¿åº¦ï¼Œé¿å… token è¶…é™
    const maxHistoryLength = 10; // ä¿ç•™æœ€è¿‘ 10 è½®å¯¹è¯
    return history.slice(-maxHistoryLength);
  }

  /**
   * ä¿å­˜å¯¹è¯å†å²
   * @param {string} userId - ç”¨æˆ·ID
   * @param {string} userMessage - ç”¨æˆ·æ¶ˆæ¯
   * @param {string} aiResponse - AI å›å¤
   */
  saveConversationHistory(userId, userMessage, aiResponse) {
    const history = this.conversationHistory.get(userId) || [];
    
    history.push(
      { role: 'user', content: userMessage },
      { role: 'assistant', content: aiResponse }
    );

    // é™åˆ¶å†å²è®°å½•é•¿åº¦
    const maxHistoryLength = 20; // æœ€å¤šä¿ç•™ 20 æ¡æ¶ˆæ¯
    if (history.length > maxHistoryLength) {
      history.splice(0, history.length - maxHistoryLength);
    }

    this.conversationHistory.set(userId, history);
  }

  /**
   * æ¸…é™¤ç”¨æˆ·å¯¹è¯å†å²
   * @param {string} userId - ç”¨æˆ·ID
   */
  clearConversationHistory(userId) {
    this.conversationHistory.delete(userId);
    logInfo('Conversation history cleared', { userId });
  }

  /**
   * è·å–é”™è¯¯æ—¶çš„å¤‡ç”¨å›å¤
   * @param {Error} error - é”™è¯¯å¯¹è±¡
   * @returns {string} å¤‡ç”¨å›å¤
   */
  getFallbackResponse(error) {
    if (error.code === 'insufficient_quota') {
      return 'æŠ±æ­‰ï¼ŒæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åå†è¯•æˆ–ç›´æ¥è”ç³»æˆ‘ä»¬çš„å®¢æœã€‚';
    }
    
    if (error.code === 'rate_limit_exceeded') {
      return 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»åå†è¯•ã€‚';
    }
    
    if (error.message?.includes('timeout')) {
      return 'è¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•ã€‚å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·è”ç³»æˆ‘ä»¬çš„å®¢æœã€‚';
    }
    
    return 'æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚è¯·ç¨åå†è¯•æˆ–ç›´æ¥è”ç³»æˆ‘ä»¬çš„å®¢æœå›¢é˜Ÿã€‚';
  }

  /**
   * æ£€æŸ¥æ˜¯å¦ä¸ºé¢„çº¦ç›¸å…³æŸ¥è¯¢
   * @param {string} message - ç”¨æˆ·æ¶ˆæ¯
   * @returns {boolean} æ˜¯å¦ä¸ºé¢„çº¦æŸ¥è¯¢
   */
  isAppointmentQuery(message) {
    const appointmentKeywords = [
      'é¢„çº¦', 'é¢„å®š', 'æŒ‚å·', 'çœ‹åŒ»ç”Ÿ', 'çœ‹ç—…', 'å°±è¯Š',
      'appointment', 'book', 'schedule', 'visit'
    ];
    
    return appointmentKeywords.some(keyword => 
      message.toLowerCase().includes(keyword.toLowerCase())
    );
  }

  /**
   * è·å–é¢„çº¦ç›¸å…³çš„æ ‡å‡†å›å¤
   * @returns {string} é¢„çº¦å›å¤
   */
  getAppointmentResponse() {
    return `æ„Ÿè°¢æ‚¨çš„å’¨è¯¢ï¼å…³äºé¢„çº¦æœåŠ¡ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»æˆ‘ä»¬ï¼š

ğŸ“ ç”µè¯é¢„çº¦ï¼šè¯·æ‹¨æ‰“æˆ‘ä»¬çš„å®¢æœçƒ­çº¿
ğŸŒ åœ¨çº¿é¢„çº¦ï¼šè®¿é—®æˆ‘ä»¬çš„å®˜ç½‘é¢„çº¦ç³»ç»Ÿ
ğŸ’¬ å®¢æœå’¨è¯¢ï¼šæˆ‘ä»¬çš„å®¢æœå›¢é˜Ÿä¼šååŠ©æ‚¨å®‰æ’

è¯·æä¾›æ‚¨çš„å§“åã€è”ç³»æ–¹å¼ã€å¸Œæœ›é¢„çº¦çš„æ—¶é—´å’ŒæœåŠ¡ç±»å‹ï¼Œæˆ‘ä»¬ä¼šå°½å¿«ä¸ºæ‚¨å®‰æ’ã€‚`;
  }

  /**
   * è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯
   * @returns {Object} ç»Ÿè®¡ä¿¡æ¯
   */
  getStats() {
    return {
      activeConversations: this.conversationHistory.size,
      totalUsers: this.conversationHistory.size,
    };
  }
}

// åˆ›å»ºå•ä¾‹å®ä¾‹
const gptService = new GPTService();

export default gptService;
